# Brain2Image

Brain2Image is a framework for generating high-resolution and semantically coherent images from EEG signals using Variational Latent Diffusion, a class of Denoising Diffusion Probabilistic Models (DDPMs). This approach combines recent progress in decoding brain signals with generative models to reconstruct realistic images from EEG signals. The model uses contrastive learning (CLIP) to generate semantically rich embeddings from the EEG signal and then generates high-resolution images of brain activity based on these embeddings. The model overcomes limitations of other generative models such as GANs, which are difficult to train and require large amounts of data. Brain2Image has potential applications in neuroscience research and clinical diagnosis of brain disorders.

## Requirements

To run this code, you will need:

- Python (3.6 or higher)
- PyTorch (1.8 or higher)
- NumPy
- Matplotlib
- Scikit-learn
- PyClip

## Installation

You can install the required Python packages using `pip`:



## Usage

To use Brain2Image, follow these steps:

1. Clone the repository:


2. Install the required packages (see above).

3. Run the code:


## Results

The results of the Brain2Image framework are presented in the paper. The framework is evaluated on the CVPR 40 dataset, and the embeddings generated by the self-supervised contrastive loss approach are shown to be effective in creating clear decision boundaries amongst various attributes of different classes. The model outperforms state-of-the-art techniques and achieves a remarkable 98% KMeans accuracy. The results demonstrate that the proposed approach can effectively classify the correct class and generate images that bear resemblance to the corresponding ground truth.

## Acknowledgments

This project is inspired by our manuscript "Brain2Image: Generating High-Resolution and Semantically Coherent Images From EEG Signals Using Variational Latent Diffusion".

## License

This project is not licensed yet.
